"""
è¿è¥æ•°æ®åˆ†æAPIï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤é¡¹ç›®ä¾èµ–ï¼‰
"""
from fastapi import APIRouter, Depends, HTTPException, status, Query, UploadFile, File, Form, Path as PathParam
from fastapi.responses import FileResponse, StreamingResponse, Response
from sqlalchemy.orm import Session
from typing import Optional, List
import asyncio
from loguru import logger
from pathlib import Path
import uuid
import base64
import json
from datetime import datetime, timedelta
from pydantic import BaseModel
from fastapi import Body

from app.api.deps import get_db
from app.schemas.common import SuccessResponse
from app.auth.dependencies import get_current_active_user
from app.models.user import User
from app.models.batch_analysis import BatchAnalysisSession, SheetReport
from app.models.custom_batch_analysis import CustomBatchAnalysisSession, CustomSheetReport
from app.models.session import AnalysisSession
from app.models.workflow import Workflow, WorkflowBinding
from app.services.workflow_service import WorkflowService
from app.services.dify_service import DifyService
from app.services.excel_service import ExcelService
from app.api.v1.operation_batch import process_all_sheets_concurrently
from app.api.v1.operation_custom_batch import process_all_custom_sheets_concurrently
from app.utils.echarts_parser import parse_echarts_from_text

router = APIRouter()

# å›ºå®šé¡¹ç›®IDï¼ˆå•é¡¹ç›®ç³»ç»Ÿï¼‰
DEFAULT_PROJECT_ID = 1


# ==================== æ•°æ®æ¨¡å‹ ====================

class ChartImage(BaseModel):
    """å›¾è¡¨å›¾ç‰‡æ•°æ®"""
    index: int
    title: str
    image: str  # Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®

class DownloadReportRequest(BaseModel):
    """ä¸‹è½½æŠ¥å‘Šè¯·æ±‚ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idï¼‰"""
    session_id: int
    chart_images: Optional[List[ChartImage]] = []

class DownloadBatchReportRequest(BaseModel):
    """ä¸‹è½½æ‰¹é‡åˆ†ææŠ¥å‘Šè¯·æ±‚ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idï¼‰"""
    chart_images: Optional[List[ChartImage]] = []


# ==================== å•æ–‡ä»¶åˆ†æAPI ====================

@router.post("/sessions", response_model=SuccessResponse)
async def create_session(
    request_data: Optional[dict] = Body(default=None),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    åˆ›å»ºæ–°çš„åˆ†æä¼šè¯ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    title = request_data.get("title") if request_data else None
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] åˆ›å»ºä¼šè¯ - user_id={current_user.id}, title={title}")
    
    try:
        # 1. è·å–å·¥ä½œæµé…ç½®ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        function_key = "operation_data_analysis"
        binding = WorkflowService.get_function_workflow(db, function_key)
        workflow_id = binding.workflow_id if binding else None
        
        # 2. ç”Ÿæˆæ ‡é¢˜
        if not title:
            title = f"æ•°æ®åˆ†æä¼šè¯_{datetime.now().strftime('%Y%m%d')}"
        
        # 3. åˆ›å»ºä¼šè¯ï¼ˆå•é¡¹ç›®ç³»ç»Ÿï¼Œä¸éœ€è¦project_idï¼‰
        conversation = AnalysisSession(
            user_id=current_user.id,
            function_key=function_key,
            workflow_id=workflow_id,
            title=title,
            messages=[]
        )
        db.add(conversation)
        db.commit()
        db.refresh(conversation)
        
        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ä¼šè¯åˆ›å»ºæˆåŠŸ - conversation_id={conversation.id}, title={conversation.title}")
        
        # 4. è¿”å›å“åº”
        return SuccessResponse(
            data={
                "id": conversation.id,
                "title": conversation.title,
                "status": "draft",
                "created_at": conversation.created_at.isoformat(),
                "updated_at": conversation.updated_at.isoformat()
            },
            message="ä¼šè¯åˆ›å»ºæˆåŠŸ"
        )
    except Exception as e:
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] åˆ›å»ºä¼šè¯å¤±è´¥ - error={str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}"
        )


@router.get("/sessions", response_model=SuccessResponse)
async def get_sessions(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    search: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–ä¼šè¯åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è·å–ä¼šè¯åˆ—è¡¨ - user_id={current_user.id}, page={page}, search={search}")
    
    try:
        # 1. æ„å»ºæŸ¥è¯¢ï¼ˆå•é¡¹ç›®ç³»ç»Ÿï¼Œä¸éœ€è¦project_idè¿‡æ»¤ï¼‰
        function_key = "operation_data_analysis"
        query = db.query(AnalysisSession).filter(
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        )
        
        # 2. æœç´¢è¿‡æ»¤
        if search:
            query = query.filter(AnalysisSession.title.ilike(f"%{search}%"))
        
        # 3. è·å–æ€»æ•°
        total = query.count()
        
        # 4. åˆ†é¡µæŸ¥è¯¢
        conversations = query.order_by(AnalysisSession.updated_at.desc()).offset(
            (page - 1) * page_size
        ).limit(page_size).all()
        
        # 5. æ„å»ºå“åº”æ•°æ®
        items = []
        for conv in conversations:
            # è®¡ç®—çŠ¶æ€
            status_val = "draft"
            if conv.messages:
                last_msg = conv.messages[-1]
                if last_msg.get("role") == "assistant":
                    try:
                        last_time_str = last_msg.get("timestamp", "")
                        if last_time_str:
                            last_time = datetime.fromisoformat(last_time_str.replace('Z', '+00:00'))
                            if last_time.tzinfo is None:
                                last_time = last_time.replace(tzinfo=None)
                                now = datetime.utcnow()
                            else:
                                now = datetime.utcnow().replace(tzinfo=None)
                                last_time = last_time.replace(tzinfo=None)
                            
                            if (now - last_time) < timedelta(hours=1):
                                status_val = "in_progress"
                            else:
                                status_val = "completed"
                        else:
                            status_val = "completed"
                    except Exception as e:
                        logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] è§£ææ¶ˆæ¯æ—¶é—´æˆ³å¤±è´¥ - conversation_id={conv.id}, error={str(e)}")
                        status_val = "completed"
                else:
                    status_val = "in_progress"
            
            items.append({
                "id": conv.id,
                "title": conv.title,
                "status": status_val,
                "created_at": conv.created_at.isoformat(),
                "updated_at": conv.updated_at.isoformat(),
                "message_count": len(conv.messages) if conv.messages else 0
            })
        
        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è·å–ä¼šè¯åˆ—è¡¨æˆåŠŸ - total={total}, items_count={len(items)}")
        
        return SuccessResponse(
            data={
                "items": items,
                "total": total,
                "page": page,
                "page_size": page_size
            }
        )
    except Exception as e:
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥ - error={str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/sessions/{id}", response_model=SuccessResponse)
async def get_session_detail(
    id: int = PathParam(..., description="ä¼šè¯ID"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¼šè¯è¯¦æƒ…ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è·å–ä¼šè¯è¯¦æƒ… - session_id={id}, user_id={current_user.id}")
    
    try:
        # 1. æŸ¥è¯¢ä¼šè¯
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨"
            )
        
        # 2. è®¡ç®—çŠ¶æ€
        status_val = "draft"
        if conversation.messages:
            last_msg = conversation.messages[-1]
            if last_msg.get("role") == "assistant":
                try:
                    last_time_str = last_msg.get("timestamp", "")
                    if last_time_str:
                        last_time = datetime.fromisoformat(last_time_str.replace('Z', '+00:00'))
                        if last_time.tzinfo is None:
                            last_time = last_time.replace(tzinfo=None)
                            now = datetime.utcnow()
                        else:
                            now = datetime.utcnow().replace(tzinfo=None)
                            last_time = last_time.replace(tzinfo=None)
                        
                        if (now - last_time) < timedelta(hours=1):
                            status_val = "in_progress"
                        else:
                            status_val = "completed"
                    else:
                        status_val = "completed"
                except Exception as e:
                    logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] è§£ææ¶ˆæ¯æ—¶é—´æˆ³å¤±è´¥ - conversation_id={conversation.id}, error={str(e)}")
                    status_val = "completed"
            else:
                status_val = "in_progress"
        
        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è·å–ä¼šè¯è¯¦æƒ…æˆåŠŸ - conversation_id={id}, messages_count={len(conversation.messages) if conversation.messages else 0}")
        
        return SuccessResponse(
            data={
                "id": conversation.id,
                "title": conversation.title,
                "status": status_val,
                "messages": conversation.messages if conversation.messages else [],
                "created_at": conversation.created_at.isoformat(),
                "updated_at": conversation.updated_at.isoformat()
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] è·å–ä¼šè¯è¯¦æƒ…å¤±è´¥ - error={str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä¼šè¯è¯¦æƒ…å¤±è´¥: {str(e)}"
        )


@router.delete("/sessions/{id}", response_model=SuccessResponse)
async def delete_session(
    id: int = PathParam(..., description="ä¼šè¯ID"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤ä¼šè¯ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    from app.models.session_version import AnalysisSessionVersion
    from app.models.dialog_history import DialogHistory
    
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] åˆ é™¤ä¼šè¯ - session_id={id}, user_id={current_user.id}")
    
    try:
        # 1. æŸ¥è¯¢ä¼šè¯
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨"
            )
        
        # 2. å…ˆåˆ é™¤æ‰€æœ‰å…³è”çš„å¯¹è¯å†å²è®°å½•
        try:
            dialog_histories = db.query(DialogHistory).filter(
                DialogHistory.session_id == id
            ).all()
            
            if dialog_histories:
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ‰¾åˆ° {len(dialog_histories)} æ¡å¯¹è¯å†å²ï¼Œå‡†å¤‡åˆ é™¤")
                for dialog in dialog_histories:
                    db.delete(dialog)
                db.flush()
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] å¯¹è¯å†å²åˆ é™¤æˆåŠŸ")
        except Exception as de:
            logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] åˆ é™¤å¯¹è¯å†å²æ—¶å‡ºé”™: {str(de)}")
        
        # 3. åˆ é™¤æ‰€æœ‰å…³è”çš„ç‰ˆæœ¬
        try:
            versions = db.query(AnalysisSessionVersion).filter(
                AnalysisSessionVersion.session_id == id
            ).all()
            
            if versions:
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ‰¾åˆ° {len(versions)} ä¸ªç‰ˆæœ¬ï¼Œå‡†å¤‡åˆ é™¤")
                for version in versions:
                    db.delete(version)
                db.flush()
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ç‰ˆæœ¬åˆ é™¤æˆåŠŸ")
        except Exception as ve:
            logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] åˆ é™¤ç‰ˆæœ¬æ—¶å‡ºé”™: {str(ve)}")
        
        # 4. åˆ é™¤ä¼šè¯
        db.delete(conversation)
        db.commit()
        
        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ä¼šè¯åˆ é™¤æˆåŠŸ - session_id={id}")
        
        return SuccessResponse(
            data={"deleted_id": id},
            message="ä¼šè¯åˆ é™¤æˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] åˆ é™¤ä¼šè¯å¤±è´¥ - session_id={id}, error={str(e)}")
        import traceback
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}"
        )


# ==================== ä¼šè¯ç‰ˆæœ¬ç®¡ç†API ====================

@router.get("/sessions/{id}/versions", response_model=SuccessResponse)
async def get_session_versions(
    id: int = PathParam(..., description="ä¼šè¯ID"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¼šè¯çš„æ‰€æœ‰ç‰ˆæœ¬åˆ—è¡¨
    """
    from app.models.session_version import AnalysisSessionVersion
    
    logger.info(f"[ç‰ˆæœ¬ç®¡ç†] è·å–ç‰ˆæœ¬åˆ—è¡¨ - session_id={id}, user_id={current_user.id}")
    
    try:
        # 1. éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. è·å–æ‰€æœ‰ç‰ˆæœ¬
        versions = db.query(AnalysisSessionVersion).filter(
            AnalysisSessionVersion.session_id == id
        ).order_by(AnalysisSessionVersion.version_no.desc()).all()
        
        # 3. æ‰¾åˆ°å½“å‰ç‰ˆæœ¬ï¼ˆæœ€æ–°çš„ï¼‰
        current_version_id = versions[0].id if versions else None
        
        # 4. æ„å»ºå“åº”æ•°æ®
        versions_data = []
        for v in versions:
            versions_data.append({
                "id": v.id,
                "version_no": v.version_no,
                "summary": v.summary,
                "created_at": v.created_at.isoformat() if v.created_at else None,
                "is_current": v.id == current_version_id
            })
        
        logger.info(f"[ç‰ˆæœ¬ç®¡ç†] è·å–ç‰ˆæœ¬åˆ—è¡¨æˆåŠŸ - session_id={id}, count={len(versions_data)}")
        
        return SuccessResponse(
            data=versions_data,
            message="è·å–ç‰ˆæœ¬åˆ—è¡¨æˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[ç‰ˆæœ¬ç®¡ç†] è·å–ç‰ˆæœ¬åˆ—è¡¨å¤±è´¥ - session_id={id}, error={str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç‰ˆæœ¬åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/sessions/{id}/versions/{version_id}", response_model=SuccessResponse)
async def get_session_version_detail(
    id: int = PathParam(..., description="ä¼šè¯ID"),
    version_id: int = PathParam(..., description="ç‰ˆæœ¬ID"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–æŸä¸ªç‰ˆæœ¬çš„è¯¦ç»†å†…å®¹
    """
    from app.models.session_version import AnalysisSessionVersion
    
    logger.info(f"[ç‰ˆæœ¬ç®¡ç†] è·å–ç‰ˆæœ¬è¯¦æƒ… - session_id={id}, version_id={version_id}, user_id={current_user.id}")
    
    try:
        # 1. éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. è·å–æŒ‡å®šç‰ˆæœ¬
        version = db.query(AnalysisSessionVersion).filter(
            AnalysisSessionVersion.id == version_id,
            AnalysisSessionVersion.session_id == id
        ).first()
        
        if not version:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ç‰ˆæœ¬ä¸å­˜åœ¨"
            )
        
        # 3. æ„å»ºå“åº”æ•°æ®
        version_data = {
            "id": version.id,
            "version_no": version.version_no,
            "summary": version.summary,
            "report_text": version.report_text,
            "report_html_charts": version.report_html_charts,
            "report_charts_json": version.report_charts_json,
            "created_at": version.created_at.isoformat() if version.created_at else None
        }
        
        logger.info(f"[ç‰ˆæœ¬ç®¡ç†] è·å–ç‰ˆæœ¬è¯¦æƒ…æˆåŠŸ - version_id={version_id}, version_no={version.version_no}")
        
        return SuccessResponse(
            data=version_data,
            message="è·å–ç‰ˆæœ¬è¯¦æƒ…æˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[ç‰ˆæœ¬ç®¡ç†] è·å–ç‰ˆæœ¬è¯¦æƒ…å¤±è´¥ - version_id={version_id}, error={str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç‰ˆæœ¬è¯¦æƒ…å¤±è´¥: {str(e)}"
        )


@router.post("/sessions/{id}/versions", response_model=SuccessResponse)
async def create_session_version(
    id: int = PathParam(..., description="ä¼šè¯ID"),
    payload: dict = Body(...),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°ç‰ˆæœ¬ï¼ˆä¿å­˜å½“å‰æŠ¥å‘ŠçŠ¶æ€ï¼‰
    payload: {
        summary?: string  # ç‰ˆæœ¬è¯´æ˜
        report_text?: string  # æŠ¥å‘Šæ–‡æœ¬å†…å®¹
        report_html_charts?: string  # HTMLå›¾è¡¨å†…å®¹
        report_charts_json?: any  # JSONå›¾è¡¨é…ç½®
    }
    """
    from app.models.session_version import AnalysisSessionVersion
    from app.services.dialog_manager import DialogManager
    
    logger.info(f"[ç‰ˆæœ¬ç®¡ç†] åˆ›å»ºæ–°ç‰ˆæœ¬ - session_id={id}, user_id={current_user.id}")
    
    try:
        # 1. éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. è·å–å½“å‰æœ€å¤§ç‰ˆæœ¬å·
        max_version = db.query(AnalysisSessionVersion).filter(
            AnalysisSessionVersion.session_id == id
        ).order_by(AnalysisSessionVersion.version_no.desc()).first()
        
        new_version_no = (max_version.version_no + 1) if max_version else 1
        
        # 3. å¦‚æœæ²¡æœ‰æä¾›æŠ¥å‘Šå†…å®¹ï¼Œå°è¯•ä»ä¼šè¯æ¶ˆæ¯ä¸­è·å–
        report_text = payload.get("report_text")
        report_html_charts = payload.get("report_html_charts")
        report_charts_json = payload.get("report_charts_json")
        
        if not report_text and conversation.messages:
            # ä»æœ€åä¸€æ¡ assistant æ¶ˆæ¯è·å–
            for msg in reversed(conversation.messages):
                if msg.get("role") == "assistant":
                    report_text = msg.get("content", "")
                    report_charts_json = msg.get("charts")
                    break
        
        # 4. åˆ›å»ºæ–°ç‰ˆæœ¬
        new_version = AnalysisSessionVersion(
            session_id=id,
            version_no=new_version_no,
            summary=payload.get("summary", f"ç‰ˆæœ¬ {new_version_no}"),
            report_text=report_text,
            report_html_charts=report_html_charts,
            report_charts_json=report_charts_json,
            created_by=current_user.id
        )
        db.add(new_version)
        db.commit()
        db.refresh(new_version)
        
        # 5. åœ¨å¯¹è¯å†å²ä¸­æ·»åŠ ç‰ˆæœ¬ä¿å­˜ç‚¹æ ‡è®°
        dialog_manager = DialogManager()
        dialog_manager.save_message_to_db(
            db=db,
            session_id=id,
            role="system",
            content=f"ğŸ“Œ ä¿å­˜ç‰ˆæœ¬ V{new_version_no}: {new_version.summary}",
            extra_data={
                "type": "version_marker",
                "version_id": new_version.id,
                "version_no": new_version_no,
                "summary": new_version.summary
            },
            version_id=new_version.id
        )
        
        logger.info(f"[ç‰ˆæœ¬ç®¡ç†] åˆ›å»ºç‰ˆæœ¬æˆåŠŸ - session_id={id}, version_id={new_version.id}, version_no={new_version_no}")
        
        return SuccessResponse(
            data={
                "id": new_version.id,
                "version_no": new_version.version_no,
                "summary": new_version.summary,
                "created_at": new_version.created_at.isoformat() if new_version.created_at else None
            },
            message=f"ç‰ˆæœ¬ V{new_version_no} åˆ›å»ºæˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[ç‰ˆæœ¬ç®¡ç†] åˆ›å»ºç‰ˆæœ¬å¤±è´¥ - session_id={id}, error={str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºç‰ˆæœ¬å¤±è´¥: {str(e)}"
        )



@router.post("/upload", response_model=SuccessResponse)
async def upload_excel(
    file: UploadFile = File(...),
    session_id: int = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    ä¸Šä¼ Excelæ–‡ä»¶ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ä¸Šä¼ æ–‡ä»¶ - session_id={session_id}, filename={file.filename}, user_id={current_user.id}")
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
        )
    
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in ['.xlsx', '.csv']:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="åªæ”¯æŒ .xlsx å’Œ .csv æ ¼å¼çš„æ–‡ä»¶"
        )
    
    # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆ10MBï¼‰
    file_content = await file.read()
    file_size = len(file_content)
    max_size = 10 * 1024 * 1024  # 10MB
    
    if file_size > max_size:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡10MB"
        )
    
    # åˆ›å»ºä¸Šä¼ ç›®å½•ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    upload_dir = Path(f"uploads/operation/project_{DEFAULT_PROJECT_ID}")
    upload_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆä½¿ç”¨session_idå’Œuuidï¼‰
    file_id_str = f"{session_id}_{uuid.uuid4().hex[:8]}"
    file_name = f"{file_id_str}{file_ext}"
    file_path = upload_dir / file_name
    
    # ä¿å­˜æ–‡ä»¶
    with open(file_path, "wb") as f:
        f.write(file_content)
    
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ–‡ä»¶ä¿å­˜æˆåŠŸ - file_path={file_path}, size={file_size}")
    
    # æ›´æ–°ä¼šè¯æ ‡é¢˜ä¸ºæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
    try:
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == session_id,
            AnalysisSession.function_key == "operation_data_analysis"
        ).first()
        
        if conversation:
            file_name_without_ext = Path(file.filename).stem
            conversation.title = file_name_without_ext
            db.commit()
            logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ä¼šè¯æ ‡é¢˜å·²æ›´æ–°ä¸ºæ–‡ä»¶å - session_id={session_id}, title={file_name_without_ext}")
    except Exception as e:
        logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] æ›´æ–°ä¼šè¯æ ‡é¢˜å¤±è´¥ - session_id={session_id}, error={str(e)}")
    
    # ä½¿ç”¨æ–‡ä»¶è·¯å¾„çš„hashä½œä¸ºfile_id
    import hashlib
    file_id_hash = int(hashlib.md5(str(file_path).encode()).hexdigest()[:8], 16) % 1000000
    
    return SuccessResponse(
        data={
            "file_id": file_id_hash,
            "file_name": file.filename,
            "file_path": str(file_path),
            "row_count": 0,
            "column_info": {}
        },
        message="æ–‡ä»¶ä¸Šä¼ æˆåŠŸ"
    )


@router.post("/generate", response_model=SuccessResponse)
async def generate_report(
    session_id: int = Form(...),
    file_id: int = Form(...),
    analysis_request: str = Form(...),
    chart_customization_prompt: str = Form(default=""),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆä½¿ç”¨é˜¿é‡Œç™¾ç‚¼APIï¼‰
    ä¸Šä¼ Excelæ–‡ä»¶åˆ°é˜¿é‡Œç™¾ç‚¼å¤§æ¨¡å‹ï¼Œç”Ÿæˆæ–‡å­—æŠ¥å‘Šå’ŒHTMLå›¾è¡¨
    """
    from app.services.bailian_service import BailianService

    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ç”ŸæˆæŠ¥å‘Š - session_id={session_id}, file_id={file_id}, user_id={current_user.id}")
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] åˆ†æéœ€æ±‚: {analysis_request[:100]}...")

    try:
        function_key = "operation_data_analysis"

        # 1. è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
        upload_dir = Path(f"uploads/operation/project_{DEFAULT_PROJECT_ID}")
        file_path = None

        if upload_dir.exists():
            for f in upload_dir.iterdir():
                if f.is_file() and str(session_id) in f.stem:
                    file_path = f
                    break

        if not file_path or not file_path.exists():
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°ä¸Šä¼ "
            )

        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ‰¾åˆ°æ–‡ä»¶ - file_path={file_path}")

        # 2. è°ƒç”¨é˜¿é‡Œç™¾ç‚¼APIç”Ÿæˆæ–‡å­—æŠ¥å‘Š
        bailian_service = BailianService()

        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è°ƒç”¨é˜¿é‡Œç™¾ç‚¼APIç”Ÿæˆæ–‡å­—æŠ¥å‘Š...")
        text_result = await bailian_service.analyze_excel_and_generate_text_report(
            file_path=str(file_path),
            user_prompt=analysis_request
        )

        if not text_result.get("success"):
            error_msg = text_result.get("error", "æ–‡å­—æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] é˜¿é‡Œç™¾ç‚¼æ–‡å­—æŠ¥å‘Šç”Ÿæˆå¤±è´¥ - {error_msg}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"æ–‡å­—æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {error_msg}"
            )

        report_text = text_result.get("text_content", "")
        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ–‡å­—æŠ¥å‘Šç”ŸæˆæˆåŠŸ - é•¿åº¦: {len(report_text)}")

        # 3. è°ƒç”¨é˜¿é‡Œç™¾ç‚¼APIç”ŸæˆHTMLå›¾è¡¨
        html_charts = ""
        if chart_customization_prompt and chart_customization_prompt.strip():
            logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è°ƒç”¨é˜¿é‡Œç™¾ç‚¼APIç”ŸæˆHTMLå›¾è¡¨...")
            html_result = await bailian_service.analyze_excel_and_generate_html(
                file_path=str(file_path),
                analysis_request=analysis_request,
                chart_customization=chart_customization_prompt
            )

            if html_result.get("success"):
                html_charts = html_result.get("html_content", "")
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] HTMLå›¾è¡¨ç”ŸæˆæˆåŠŸ - é•¿åº¦: {len(html_charts)}")
            else:
                logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] HTMLå›¾è¡¨ç”Ÿæˆå¤±è´¥: {html_result.get('error')}")
        else:
            # æ²¡æœ‰å›¾è¡¨å®šåˆ¶éœ€æ±‚æ—¶ï¼Œä¹Ÿå°è¯•ç”Ÿæˆé»˜è®¤å›¾è¡¨
            logger.info(f"[è¿è¥æ•°æ®åˆ†æ] è°ƒç”¨é˜¿é‡Œç™¾ç‚¼APIç”Ÿæˆé»˜è®¤HTMLå›¾è¡¨...")
            html_result = await bailian_service.analyze_excel_and_generate_html(
                file_path=str(file_path),
                analysis_request=analysis_request,
                chart_customization=None
            )

            if html_result.get("success"):
                html_charts = html_result.get("html_content", "")
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] é»˜è®¤HTMLå›¾è¡¨ç”ŸæˆæˆåŠŸ - é•¿åº¦: {len(html_charts)}")
            else:
                logger.warning(f"[è¿è¥æ•°æ®åˆ†æ] é»˜è®¤HTMLå›¾è¡¨ç”Ÿæˆå¤±è´¥: {html_result.get('error')}")

        # 5. è§£æechartsä»£ç å—ï¼ˆå¦‚æœæœ‰ï¼‰
        cleaned_text, charts = parse_echarts_from_text(report_text)

        # 6. æ„å»ºæŠ¥å‘Šå†…å®¹
        report_content = {
            "text": cleaned_text,
            "charts": charts,
            "html_charts": html_charts,  # é˜¿é‡Œç™¾ç‚¼ç”Ÿæˆçš„HTMLå›¾è¡¨
            "tables": [],
            "metrics": {}
        }

        # å¦‚æœæ¸…ç†åçš„æ–‡æœ¬æ˜¯JSONæ ¼å¼ï¼Œå°è¯•è§£æ
        if cleaned_text and (cleaned_text.startswith("{") or cleaned_text.startswith("[")):
            try:
                parsed = json.loads(cleaned_text)
                if isinstance(parsed, dict):
                    parsed_charts = parsed.get("charts", [])
                    if parsed_charts and not charts:
                        report_content["charts"] = parsed_charts
                    for key in ["tables", "metrics"]:
                        if key in parsed:
                            report_content[key] = parsed[key]
            except:
                pass

        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æŠ¥å‘Šç”ŸæˆæˆåŠŸ - text_length={len(cleaned_text)}, charts_count={len(charts)}, html_charts_length={len(html_charts)}")
        
        # 8. ä¿å­˜å¯¹è¯æ¶ˆæ¯åˆ°ä¼šè¯è®°å½•
        try:
            conversation = db.query(AnalysisSession).filter(
                AnalysisSession.id == session_id,
                AnalysisSession.function_key == function_key
            ).first()
            
            if conversation:
                user_message = {
                    "role": "user",
                    "content": analysis_request,
                    "timestamp": datetime.utcnow().isoformat(),
                    "file_name": file_path.name if file_path else None
                }
                
                assistant_message = {
                    "role": "assistant",
                    "content": cleaned_text,
                    "timestamp": datetime.utcnow().isoformat()
                }
                
                if charts:
                    assistant_message["charts"] = charts
                
                if html_charts:
                    assistant_message["html_charts"] = html_charts
                
                if report_content.get("tables"):
                    assistant_message["tables"] = report_content["tables"]
                
                if not conversation.messages:
                    conversation.messages = []
                conversation.messages.append(user_message)
                conversation.messages.append(assistant_message)
                
                if conversation.title.startswith("æ•°æ®åˆ†æä¼šè¯_"):
                    if user_message.get("file_name"):
                        file_name_without_ext = Path(user_message["file_name"]).stem
                        conversation.title = file_name_without_ext
                
                db.commit()
                logger.info(f"[è¿è¥æ•°æ®åˆ†æ] å¯¹è¯æ¶ˆæ¯å·²ä¿å­˜åˆ°ä¼šè¯ - session_id={session_id}, messages_count={len(conversation.messages)}")
        except Exception as e:
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] ä¿å­˜å¯¹è¯æ¶ˆæ¯å¤±è´¥ - session_id={session_id}, error={str(e)}")
        
        # 9. è¿”å›æŠ¥å‘Š
        report_id = uuid.uuid4().hex
        
        return SuccessResponse(
            data={
                "report_id": report_id,
                "content": report_content
            },
            message="æŠ¥å‘Šç”ŸæˆæˆåŠŸ"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_detail = str(e)
        import traceback
        error_traceback = traceback.format_exc()
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] ç”ŸæˆæŠ¥å‘Šå¼‚å¸¸ - {error_detail}")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] å¼‚å¸¸å †æ ˆ:\n{error_traceback}")

        error_msg = f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {error_detail}"
        if "dashscope" in error_detail.lower() or "bailian" in error_detail.lower() or "api" in error_detail.lower():
            error_msg = f"é˜¿é‡Œç™¾ç‚¼APIè°ƒç”¨é”™è¯¯: {error_detail}"
        elif "file" in error_detail.lower():
            error_msg = f"æ–‡ä»¶å¤„ç†é”™è¯¯: {error_detail}"
        elif "excel" in error_detail.lower():
            error_msg = f"Excelè¯»å–é”™è¯¯: {error_detail}"

        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=error_msg
        )


@router.post("/charts/modify", response_model=SuccessResponse)
async def modify_chart(
    session_id: int = Form(...),
    current_html: str = Form(...),
    color: Optional[str] = Form(None),
    chart_type: Optional[str] = Form(None),
    ai_instruction: Optional[str] = Form(None),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    ä¿®æ”¹å›¾è¡¨
    
    Args:
        session_id: ä¼šè¯ID
        current_html: å½“å‰å›¾è¡¨çš„HTMLä»£ç 
        color: é¢œè‰²ä¿®æ”¹ï¼ˆå¦‚ #409effï¼‰
        chart_type: å›¾è¡¨ç±»å‹ï¼ˆbar/line/pieï¼‰
        ai_instruction: AIè‡ªç”±ä¿®æ”¹æŒ‡ä»¤
    """
    from app.services.chart_modification_service import ChartModificationService
    
    logger.info(f"[å›¾è¡¨ä¿®æ”¹] æ”¶åˆ°ä¿®æ”¹è¯·æ±‚ - session_id={session_id}, user_id={current_user.id}")
    logger.info(f"[å›¾è¡¨ä¿®æ”¹] ä¿®æ”¹å‚æ•° - color={color}, type={chart_type}, ai={ai_instruction[:50] if ai_instruction else None}")
    
    try:
        # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == session_id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # è°ƒç”¨å›¾è¡¨ä¿®æ”¹æœåŠ¡
        chart_service = ChartModificationService()
        result = await chart_service.modify_chart(
            current_html=current_html,
            color=color,
            chart_type=chart_type,
            ai_instruction=ai_instruction
        )
        
        if not result.get("success"):
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=result.get("error", "å›¾è¡¨ä¿®æ”¹å¤±è´¥")
            )
        
        logger.info(f"[å›¾è¡¨ä¿®æ”¹] ä¿®æ”¹æˆåŠŸ - session_id={session_id}")
        
        return SuccessResponse(
            data={
                "html": result.get("html")
            },
            message="å›¾è¡¨ä¿®æ”¹æˆåŠŸ"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[å›¾è¡¨ä¿®æ”¹] ä¿®æ”¹å¤±è´¥ - error={str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å›¾è¡¨ä¿®æ”¹å¤±è´¥: {str(e)}"
        )


@router.post("/reports/{report_id}/download")
async def download_report_pdf(
    report_id: str = PathParam(..., description="æŠ¥å‘ŠIDï¼ˆå®é™…ä½¿ç”¨session_idè·å–æŠ¥å‘Šï¼‰"),
    request_data: DownloadReportRequest = Body(...),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    ä¸‹è½½æŠ¥å‘ŠPDFï¼ˆæ”¯æŒå›¾è¡¨å›¾ç‰‡ï¼‰ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    import traceback
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ====== å¼€å§‹ä¸‹è½½æŠ¥å‘ŠPDF ======")
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] report_id={report_id}, session_id={request_data.session_id}, user_id={current_user.id}")
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ”¶åˆ° {len(request_data.chart_images)} ä¸ªå›¾è¡¨å›¾ç‰‡")
    
    try:
        # 1. ä»ä¼šè¯è®°å½•ä¸­è·å–æŠ¥å‘Šå†…å®¹ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == request_data.session_id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] ä¼šè¯ä¸å­˜åœ¨ - session_id={request_data.session_id}, user_id={current_user.id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        logger.info(f"[è¿è¥æ•°æ®åˆ†æ] æ‰¾åˆ°ä¼šè¯ - conversation_id={conversation.id}, title={conversation.title}, messages_count={len(conversation.messages) if conversation.messages else 0}")
        
        # 2. ä»æœ€åä¸€æ¡assistantæ¶ˆæ¯ä¸­è·å–æŠ¥å‘Šå†…å®¹
        report_content = None
        try:
            if conversation.messages:
                assistant_messages = [msg for msg in conversation.messages if msg.get("role") == "assistant"]
                if assistant_messages:
                    last_assistant_msg = assistant_messages[-1]
                    report_content = {
                        "text": str(last_assistant_msg.get("content", "")),
                        "charts": last_assistant_msg.get("charts", []) or [],
                        "tables": last_assistant_msg.get("tables", []) or [],
                        "metrics": last_assistant_msg.get("metrics", {}) or {}
                    }
        except Exception as e:
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] è·å–æŠ¥å‘Šå†…å®¹æ—¶å‡ºé”™: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"è·å–æŠ¥å‘Šå†…å®¹å¤±è´¥: {str(e)}"
            )
        
        if not report_content:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æŠ¥å‘Šå†…å®¹ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”ŸæˆæŠ¥å‘Š"
            )
        
        if not report_content.get("text"):
            report_content["text"] = "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
        
        # 3. å¤„ç†å›¾è¡¨å›¾ç‰‡
        chart_images_data = []
        if request_data.chart_images:
            for chart_img in request_data.chart_images:
                try:
                    image_data = chart_img.image.split(',')[1] if ',' in chart_img.image else chart_img.image
                    chart_images_data.append({
                        'index': chart_img.index,
                        'title': chart_img.title,
                        'image_data': image_data
                    })
                except Exception as e:
                    logger.error(f"[è¿è¥æ•°æ®åˆ†æ] âœ— è§£æå›¾è¡¨å›¾ç‰‡å¤±è´¥: {str(e)}")
        
        # 4. ç”ŸæˆPDF
        try:
            from app.utils.pdf_generator import generate_report_pdf
            
            pdf_bytes = generate_report_pdf(
                title=str(conversation.title or "æ•°æ®åˆ†ææŠ¥å‘Š"),
                report_content=report_content,
                session_id=request_data.session_id,
                chart_images=chart_images_data
            )
            logger.info(f"[è¿è¥æ•°æ®åˆ†æ] PDFç”ŸæˆæˆåŠŸ - å¤§å°: {len(pdf_bytes)} bytes")
        except Exception as e:
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] PDFç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"PDFç”Ÿæˆå¤±è´¥: {str(e)}"
            )
        
        # 5. è¿”å›PDFæ–‡ä»¶
        filename = f"{conversation.title or 'æ•°æ®åˆ†ææŠ¥å‘Š'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        
        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"'
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_traceback = traceback.format_exc()
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] ====== PDFä¸‹è½½å¤±è´¥ ======")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] é”™è¯¯æ¶ˆæ¯: {str(e)}")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] å®Œæ•´å †æ ˆ:\n{error_traceback}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç”ŸæˆPDFå¤±è´¥: {str(e)}"
        )


@router.get("/reports/{report_id}/download-image")
async def download_report_image(
    report_id: str = PathParam(..., description="æŠ¥å‘ŠIDï¼ˆå®é™…ä½¿ç”¨session_idè·å–æŠ¥å‘Šï¼‰"),
    session_id: int = Query(..., description="ä¼šè¯ID"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    ä¸‹è½½æŠ¥å‘Šå›¾ç‰‡ï¼ˆPNGæ ¼å¼ï¼Œé¿å…PDFä¸­æ–‡ä¹±ç é—®é¢˜ï¼‰ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    import traceback
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ====== å¼€å§‹ä¸‹è½½æŠ¥å‘Šå›¾ç‰‡ ======")
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] report_id={report_id}, session_id={session_id}, user_id={current_user.id}")
    
    try:
        # 1. ä»ä¼šè¯è®°å½•ä¸­è·å–æŠ¥å‘Šå†…å®¹ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == session_id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. ä»æœ€åä¸€æ¡assistantæ¶ˆæ¯ä¸­è·å–æŠ¥å‘Šå†…å®¹
        report_content = None
        try:
            if conversation.messages:
                assistant_messages = [msg for msg in conversation.messages if msg.get("role") == "assistant"]
                if assistant_messages:
                    last_assistant_msg = assistant_messages[-1]
                    report_content = {
                        "text": str(last_assistant_msg.get("content", "")),
                        "charts": last_assistant_msg.get("charts", []) or [],
                        "tables": last_assistant_msg.get("tables", []) or [],
                        "metrics": last_assistant_msg.get("metrics", {}) or {}
                    }
        except Exception as e:
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] è·å–æŠ¥å‘Šå†…å®¹æ—¶å‡ºé”™: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"è·å–æŠ¥å‘Šå†…å®¹å¤±è´¥: {str(e)}"
            )
        
        if not report_content:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æŠ¥å‘Šå†…å®¹ä¸å­˜åœ¨ï¼Œè¯·å…ˆç”ŸæˆæŠ¥å‘Š"
            )
        
        if not report_content.get("text"):
            report_content["text"] = "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
        
        # 3. ç”Ÿæˆå›¾ç‰‡
        try:
            from app.utils.image_generator import generate_report_image
            
            image_bytes = generate_report_image(
                title=str(conversation.title or "æ•°æ®åˆ†ææŠ¥å‘Š"),
                report_content=report_content,
                session_id=session_id
            )
            logger.info(f"[è¿è¥æ•°æ®åˆ†æ] å›¾ç‰‡ç”ŸæˆæˆåŠŸ - å¤§å°: {len(image_bytes)} bytes")
        except Exception as e:
            logger.error(f"[è¿è¥æ•°æ®åˆ†æ] å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}"
            )
        
        # 4. è¿”å›å›¾ç‰‡æ–‡ä»¶
        filename = f"{conversation.title or 'æ•°æ®åˆ†ææŠ¥å‘Š'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        
        return Response(
            content=image_bytes,
            media_type="image/png",
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"'
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_traceback = traceback.format_exc()
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] ====== å›¾ç‰‡ä¸‹è½½å¤±è´¥ ======")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] é”™è¯¯æ¶ˆæ¯: {str(e)}")
        logger.error(f"[è¿è¥æ•°æ®åˆ†æ] å®Œæ•´å †æ ˆ:\n{error_traceback}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {str(e)}"
        )


@router.get("/template")
async def download_template(
    current_user: User = Depends(get_current_active_user)
):
    """
    ä¸‹è½½Excelæ¨¡æ¿
    """
    logger.info(f"[è¿è¥æ•°æ®åˆ†æ] ä¸‹è½½æ¨¡æ¿ - user_id={current_user.id}")
    
    # TODO: ç”ŸæˆExcelæ¨¡æ¿æ–‡ä»¶å¹¶è¿”å›
    raise HTTPException(
        status_code=status.HTTP_501_NOT_IMPLEMENTED,
        detail="æ¨¡æ¿ä¸‹è½½åŠŸèƒ½å¾…å®ç°"
    )


# ==================== æ‰¹é‡åˆ†æç›¸å…³API ====================

@router.post("/batch/upload", response_model=SuccessResponse)
async def upload_batch_excel(
    file: UploadFile = File(...),
    analysis_request: str = Form("ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    ä¸Šä¼ å¤šSheet Excelæ–‡ä»¶å¹¶æ‹†åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    æ‹†åˆ†å®Œæˆåè‡ªåŠ¨å¼€å§‹æ‰¹é‡åˆ†æ
    """
    logger.info(f"[æ‰¹é‡åˆ†æ] ä¸Šä¼ æ–‡ä»¶ - filename={file.filename}, user_id={current_user.id}")
    
    # 1. éªŒè¯æ–‡ä»¶
    if not file.filename:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
        )
    
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in ['.xlsx']:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ‰¹é‡åˆ†æåªæ”¯æŒ .xlsx æ ¼å¼çš„æ–‡ä»¶"
        )
    
    # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆ20MBï¼‰
    file_content = await file.read()
    file_size = len(file_content)
    max_size = 20 * 1024 * 1024  # 20MB
    
    if file_size > max_size:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡20MB"
        )
    
    try:
        # 2. åˆ›å»ºæ‰¹é‡ä¼šè¯è®°å½•ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = BatchAnalysisSession(
            user_id=current_user.id,
            original_file_name=file.filename,
            original_file_path="",
            split_files_dir="",
            sheet_count=0,
            status="processing"
        )
        db.add(batch_session)
        db.flush()
        
        batch_session_id = batch_session.id
        logger.info(f"[æ‰¹é‡åˆ†æ] åˆ›å»ºæ‰¹é‡ä¼šè¯ - batch_session_id={batch_session_id}")
        
        # 3. ä¿å­˜åŸå§‹æ–‡ä»¶
        batch_dir = Path(f"uploads/operation/project_{DEFAULT_PROJECT_ID}/batch/batch_{batch_session_id}")
        original_dir = batch_dir / "original"
        sheets_dir = batch_dir / "sheets"
        
        original_dir.mkdir(parents=True, exist_ok=True)
        sheets_dir.mkdir(parents=True, exist_ok=True)
        
        original_file_path = original_dir / file.filename
        with open(original_file_path, "wb") as f:
            f.write(file_content)
        
        logger.info(f"[æ‰¹é‡åˆ†æ] åŸå§‹æ–‡ä»¶å·²ä¿å­˜ - path={original_file_path}")
        
        # 4. æ‹†åˆ†Excelæ–‡ä»¶
        logger.info(f"[æ‰¹é‡åˆ†æ] å¼€å§‹æ‹†åˆ†Excelæ–‡ä»¶...")
        split_files = ExcelService.split_excel_file(
            source_file_path=str(original_file_path),
            output_dir=sheets_dir,
            batch_session_id=batch_session_id
        )
        
        sheet_count = len(split_files)
        logger.info(f"[æ‰¹é‡åˆ†æ] æ‹†åˆ†å®Œæˆ - sheet_count={sheet_count}")
        
        # éªŒè¯æ‰€æœ‰æ‹†åˆ†æ–‡ä»¶éƒ½å­˜åœ¨
        for sheet_info in split_files:
            split_path = Path(sheet_info["split_file_path"])
            if not split_path.exists():
                logger.error(f"[æ‰¹é‡åˆ†æ] æ‹†åˆ†æ–‡ä»¶ä¸å­˜åœ¨: {split_path}")
                raise Exception(f"æ‹†åˆ†æ–‡ä»¶ä¸å­˜åœ¨: {split_path}")
        
        # 5. æ›´æ–°æ‰¹é‡ä¼šè¯è®°å½•
        batch_session.original_file_path = str(original_file_path)
        batch_session.split_files_dir = str(sheets_dir)
        batch_session.sheet_count = sheet_count
        
        # 6. ä¸ºæ¯ä¸ªSheetåˆ›å»ºæŠ¥å‘Šè®°å½•
        sheet_reports = []
        for sheet_info in split_files:
            sheet_report = SheetReport(
                batch_session_id=batch_session_id,
                sheet_name=sheet_info["sheet_name"],
                sheet_index=sheet_info["sheet_index"],
                split_file_path=sheet_info["split_file_path"],
                report_status="pending"
            )
            db.add(sheet_report)
            sheet_reports.append(sheet_report)
        
        db.commit()
        logger.info(f"[æ‰¹é‡åˆ†æ] æ‰¹é‡ä¼šè¯å’ŒSheetæŠ¥å‘Šè®°å½•å·²åˆ›å»º")
        
        # 7. è¿”å›ç»“æœ
        return SuccessResponse(
            data={
                "batch_session_id": batch_session_id,
                "sheet_count": sheet_count,
                "sheets": [
                    {
                        "id": sr.id,
                        "sheet_name": sr.sheet_name,
                        "sheet_index": sr.sheet_index,
                        "split_file_path": sr.split_file_path,
                        "report_status": sr.report_status
                    }
                    for sr in sheet_reports
                ],
                "status": batch_session.status
            },
            message="æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå·²æ‹†åˆ†å®Œæˆ"
        )
    
    except Exception as e:
        db.rollback()
        logger.error(f"[æ‰¹é‡åˆ†æ] ä¸Šä¼ å’Œæ‹†åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ–‡ä»¶ä¸Šä¼ å’Œæ‹†åˆ†å¤±è´¥: {str(e)}"
        )


@router.post("/batch/analyze", response_model=SuccessResponse)
async def start_batch_analysis(
    batch_session_id: int = Form(...),
    analysis_request: str = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    å¼€å§‹æ‰¹é‡åˆ†æï¼ˆå¼‚æ­¥å¤„ç†ï¼‰ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    å¤ç”¨ç°æœ‰çš„ generate_report é€»è¾‘ï¼Œå¯¹æ¯ä¸ªSheeté‡å¤è°ƒç”¨
    """
    logger.info(f"[æ‰¹é‡åˆ†æ] å¼€å§‹æ‰¹é‡åˆ†æ - batch_session_id={batch_session_id}, user_id={current_user.id}")
    
    try:
        # 1. è·å–æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = db.query(BatchAnalysisSession).filter(
            BatchAnalysisSession.id == batch_session_id,
            BatchAnalysisSession.user_id == current_user.id
        ).first()
        
        if not batch_session:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æ‰¹é‡ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. è·å–æ‰€æœ‰å¾…å¤„ç†çš„SheetæŠ¥å‘Š
        sheet_reports = db.query(SheetReport).filter(
            SheetReport.batch_session_id == batch_session_id,
            SheetReport.report_status == "pending"
        ).order_by(SheetReport.sheet_index).all()
        
        if not sheet_reports:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ²¡æœ‰å¾…å¤„ç†çš„SheetæŠ¥å‘Š"
            )
        
        logger.info(f"[æ‰¹é‡åˆ†æ] æ‰¾åˆ° {len(sheet_reports)} ä¸ªå¾…å¤„ç†çš„Sheet")
        
        # 3. æ›´æ–°æ‰¹é‡ä¼šè¯çŠ¶æ€
        batch_session.status = "processing"
        db.commit()
        
        # 4. å¯åŠ¨å¼‚æ­¥ä»»åŠ¡å¤„ç†æ¯ä¸ªSheet
        async def run_batch_analysis():
            """åå°å¼‚æ­¥ä»»åŠ¡"""
            try:
                from app.core.database import SessionLocal
                background_db = SessionLocal()
                
                try:
                    background_sheet_reports = background_db.query(SheetReport).filter(
                        SheetReport.batch_session_id == batch_session_id
                    ).order_by(SheetReport.sheet_index).all()
                    
                    # å¹¶å‘å¤„ç†æ‰€æœ‰Sheetï¼ˆç§»é™¤project_idå‚æ•°ï¼‰
                    results = await process_all_sheets_concurrently(
                        sheet_reports=background_sheet_reports,
                        analysis_request=analysis_request,
                        user_id=current_user.id,
                        batch_session_id=batch_session_id,
                        db=background_db
                    )
                    
                    # æ›´æ–°æ‰¹é‡ä¼šè¯çŠ¶æ€
                    background_batch_session = background_db.query(BatchAnalysisSession).filter(
                        BatchAnalysisSession.id == batch_session_id
                    ).first()
                    
                    if background_batch_session:
                        completed_count = background_db.query(SheetReport).filter(
                            SheetReport.batch_session_id == batch_session_id,
                            SheetReport.report_status == "completed"
                        ).count()
                        
                        failed_count = background_db.query(SheetReport).filter(
                            SheetReport.batch_session_id == batch_session_id,
                            SheetReport.report_status == "failed"
                        ).count()
                        
                        total_count = background_batch_session.sheet_count
                        
                        if completed_count == total_count:
                            background_batch_session.status = "completed"
                        elif failed_count == total_count:
                            background_batch_session.status = "failed"
                        elif failed_count > 0:
                            background_batch_session.status = "partial_failed"
                        else:
                            background_batch_session.status = "processing"
                        
                        background_db.commit()
                        logger.info(f"[æ‰¹é‡åˆ†æ] æ‰¹é‡åˆ†æå®Œæˆ - batch_session_id={batch_session_id}, completed={completed_count}, failed={failed_count}")
                
                finally:
                    background_db.close()
            
            except Exception as e:
                logger.error(f"[æ‰¹é‡åˆ†æ] åå°ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
                from app.core.database import SessionLocal
                error_db = SessionLocal()
                try:
                    error_batch_session = error_db.query(BatchAnalysisSession).filter(
                        BatchAnalysisSession.id == batch_session_id
                    ).first()
                    if error_batch_session:
                        error_batch_session.status = "failed"
                        error_db.commit()
                finally:
                    error_db.close()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        asyncio.create_task(run_batch_analysis())
        
        # 5. è¿”å›å¤„ç†çŠ¶æ€
        return SuccessResponse(
            data={
                "batch_session_id": batch_session_id,
                "status": "processing",
                "total_sheets": len(sheet_reports),
                "completed_sheets": 0
            },
            message="æ‰¹é‡åˆ†æå·²å¼€å§‹ï¼Œæ­£åœ¨åå°å¤„ç†"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[æ‰¹é‡åˆ†æ] å¯åŠ¨æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯åŠ¨æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}"
        )


@router.get("/batch/{batch_session_id}/status", response_model=SuccessResponse)
async def get_batch_analysis_status(
    batch_session_id: int = PathParam(..., description="æ‰¹é‡ä¼šè¯ID"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–æ‰¹é‡åˆ†æçŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[æ‰¹é‡åˆ†æ] æŸ¥è¯¢çŠ¶æ€ - batch_session_id={batch_session_id}, user_id={current_user.id}")
    
    # 1. è·å–æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    batch_session = db.query(BatchAnalysisSession).filter(
        BatchAnalysisSession.id == batch_session_id,
        BatchAnalysisSession.user_id == current_user.id
    ).first()
    
    if not batch_session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ‰¹é‡ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    # 2. è·å–æ‰€æœ‰SheetæŠ¥å‘Š
    sheet_reports = db.query(SheetReport).filter(
        SheetReport.batch_session_id == batch_session_id
    ).order_by(SheetReport.sheet_index).all()
    
    # 3. ç»Ÿè®¡çŠ¶æ€
    total_sheets = len(sheet_reports)
    completed_sheets = sum(1 for sr in sheet_reports if sr.report_status == "completed")
    failed_sheets = sum(1 for sr in sheet_reports if sr.report_status == "failed")
    generating_sheets = sum(1 for sr in sheet_reports if sr.report_status == "generating")
    
    # 4. æ„å»ºæŠ¥å‘Šåˆ—è¡¨
    reports_data = []
    for sr in sheet_reports:
        report_data = {
            "id": sr.id,
            "sheet_name": sr.sheet_name,
            "sheet_index": sr.sheet_index,
            "report_status": sr.report_status,
        }
        
        if sr.report_status == "completed" and sr.report_content:
            report_data["report_content"] = sr.report_content
        elif sr.report_status == "failed" and sr.error_message:
            report_data["error_message"] = sr.error_message
        
        reports_data.append(report_data)
    
    return SuccessResponse(
        data={
            "batch_session_id": batch_session_id,
            "status": batch_session.status,
            "total_sheets": total_sheets,
            "completed_sheets": completed_sheets,
            "failed_sheets": failed_sheets,
            "generating_sheets": generating_sheets,
            "pending_sheets": total_sheets - completed_sheets - failed_sheets - generating_sheets,
            "reports": reports_data
        },
        message="çŠ¶æ€æŸ¥è¯¢æˆåŠŸ"
    )


@router.get("/batch/reports/{report_id}", response_model=SuccessResponse)
async def get_sheet_report(
    report_id: int = PathParam(..., description="æŠ¥å‘ŠID"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–å•ä¸ªæŠ¥å‘Šè¯¦æƒ…ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[æ‰¹é‡åˆ†æ] æŸ¥è¯¢æŠ¥å‘Šè¯¦æƒ… - report_id={report_id}, user_id={current_user.id}")
    
    # 1. è·å–æŠ¥å‘Š
    sheet_report = db.query(SheetReport).filter(
        SheetReport.id == report_id
    ).first()
    
    if not sheet_report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨"
        )
    
    # 2. éªŒè¯æƒé™ï¼ˆé€šè¿‡æ‰¹é‡ä¼šè¯éªŒè¯ï¼Œä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    batch_session = db.query(BatchAnalysisSession).filter(
        BatchAnalysisSession.id == sheet_report.batch_session_id,
        BatchAnalysisSession.user_id == current_user.id
    ).first()
    
    if not batch_session:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒé™è®¿é—®æ­¤æŠ¥å‘Š"
        )
    
    # 3. æ„å»ºå“åº”æ•°æ®
    report_data = {
        "id": sheet_report.id,
        "sheet_name": sheet_report.sheet_name,
        "sheet_index": sheet_report.sheet_index,
        "report_status": sheet_report.report_status,
        "report_content": sheet_report.report_content or {},
        "error_message": sheet_report.error_message,
        "created_at": sheet_report.created_at.isoformat() if sheet_report.created_at else None,
        "updated_at": sheet_report.updated_at.isoformat() if sheet_report.updated_at else None
    }
    
    return SuccessResponse(
        data=report_data,
        message="æŠ¥å‘ŠæŸ¥è¯¢æˆåŠŸ"
    )


@router.post("/batch/reports/{report_id}/download")
async def download_batch_report_pdf(
    report_id: int = PathParam(..., description="æŠ¥å‘ŠID"),
    request_data: DownloadBatchReportRequest = Body(...),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    ä¸‹è½½æ‰¹é‡åˆ†ææŠ¥å‘ŠPDFï¼ˆæ”¯æŒå›¾è¡¨å›¾ç‰‡ï¼‰ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    import traceback
    logger.info(f"[æ‰¹é‡åˆ†æ] ====== å¼€å§‹ä¸‹è½½æŠ¥å‘ŠPDF ======")
    logger.info(f"[æ‰¹é‡åˆ†æ] report_id={report_id}, user_id={current_user.id}")
    logger.info(f"[æ‰¹é‡åˆ†æ] æ”¶åˆ° {len(request_data.chart_images) if request_data.chart_images else 0} ä¸ªå›¾è¡¨å›¾ç‰‡")
    
    try:
        # 1. è·å–SheetæŠ¥å‘Š
        sheet_report = db.query(SheetReport).filter(
            SheetReport.id == report_id
        ).first()
        
        if not sheet_report:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æŠ¥å‘Šä¸å­˜åœ¨"
            )
        
        # 2. éªŒè¯æƒé™ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = db.query(BatchAnalysisSession).filter(
            BatchAnalysisSession.id == sheet_report.batch_session_id,
            BatchAnalysisSession.user_id == current_user.id
        ).first()
        
        if not batch_session:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒé™è®¿é—®æ­¤æŠ¥å‘Š"
            )
        
        # 3. æ£€æŸ¥æŠ¥å‘ŠçŠ¶æ€å’Œå†…å®¹
        if sheet_report.report_status != "completed":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"æŠ¥å‘Šå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {sheet_report.report_status}"
            )
        
        if not sheet_report.report_content:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æŠ¥å‘Šå†…å®¹ä¸å­˜åœ¨"
            )
        
        # 4. è·å–æŠ¥å‘Šå†…å®¹
        report_content = {
            "text": str(sheet_report.report_content.get("text", "")),
            "charts": sheet_report.report_content.get("charts", []) or [],
            "tables": sheet_report.report_content.get("tables", []) or [],
            "metrics": sheet_report.report_content.get("metrics", {}) or {}
        }
        
        if not report_content.get("text"):
            report_content["text"] = "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
        
        # 5. å¤„ç†å›¾è¡¨å›¾ç‰‡
        chart_images_data = []
        if request_data.chart_images:
            for chart_img in request_data.chart_images:
                try:
                    image_data = chart_img.image.split(',')[1] if ',' in chart_img.image else chart_img.image
                    chart_images_data.append({
                        'index': chart_img.index,
                        'title': chart_img.title,
                        'image_data': image_data
                    })
                except Exception as e:
                    logger.error(f"[æ‰¹é‡åˆ†æ] âœ— è§£æå›¾è¡¨å›¾ç‰‡å¤±è´¥: {str(e)}")
        
        # 6. ç”ŸæˆPDF
        try:
            from app.utils.pdf_generator import generate_report_pdf
            
            report_title = f"{sheet_report.sheet_name} - æ•°æ®åˆ†ææŠ¥å‘Š"
            pdf_bytes = generate_report_pdf(
                title=report_title,
                report_content=report_content,
                session_id=sheet_report.batch_session_id,
                chart_images=chart_images_data
            )
            logger.info(f"[æ‰¹é‡åˆ†æ] PDFç”ŸæˆæˆåŠŸ - å¤§å°: {len(pdf_bytes)} bytes")
        except Exception as e:
            logger.error(f"[æ‰¹é‡åˆ†æ] PDFç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"PDFç”Ÿæˆå¤±è´¥: {str(e)}"
            )
        
        # 7. è¿”å›PDFæ–‡ä»¶
        filename = f"{sheet_report.sheet_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        
        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"'
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_traceback = traceback.format_exc()
        logger.error(f"[æ‰¹é‡åˆ†æ] ====== PDFä¸‹è½½å¤±è´¥ ======")
        logger.error(f"[æ‰¹é‡åˆ†æ] é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"[æ‰¹é‡åˆ†æ] é”™è¯¯æ¶ˆæ¯: {str(e)}")
        logger.error(f"[æ‰¹é‡åˆ†æ] å®Œæ•´å †æ ˆ:\n{error_traceback}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç”ŸæˆPDFå¤±è´¥: {str(e)}"
        )


@router.post("/batch/sessions", response_model=SuccessResponse)
async def create_batch_session(
    request_data: Optional[dict] = Body(default=None),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    åˆ›å»ºæ–°çš„æ‰¹é‡åˆ†æä¼šè¯ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    title = request_data.get("title") if request_data else None
    logger.info(f"[æ‰¹é‡åˆ†æ] åˆ›å»ºä¼šè¯ - user_id={current_user.id}, title={title}")
    
    try:
        # ç”Ÿæˆæ ‡é¢˜
        if not title:
            title = f"æ‰¹é‡åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # åˆ›å»ºæ‰¹é‡ä¼šè¯ï¼ˆåˆå§‹çŠ¶æ€ä¸ºdraftï¼Œç­‰å¾…ä¸Šä¼ æ–‡ä»¶ï¼‰
        batch_session = BatchAnalysisSession(
            user_id=current_user.id,
            original_file_name=title,
            original_file_path="",
            split_files_dir="",
            sheet_count=0,
            status="draft"  # è‰ç¨¿çŠ¶æ€ï¼Œç­‰å¾…ä¸Šä¼ æ–‡ä»¶
        )
        db.add(batch_session)
        db.commit()
        db.refresh(batch_session)
        
        logger.info(f"[æ‰¹é‡åˆ†æ] ä¼šè¯åˆ›å»ºæˆåŠŸ - batch_session_id={batch_session.id}, title={batch_session.original_file_name}")
        
        # è¿”å›å“åº”
        return SuccessResponse(
            data={
                "id": batch_session.id,
                "original_file_name": batch_session.original_file_name,
                "sheet_count": batch_session.sheet_count,
                "status": batch_session.status,
                "created_at": batch_session.created_at.isoformat() if batch_session.created_at else None,
                "updated_at": batch_session.updated_at.isoformat() if batch_session.updated_at else None
            },
            message="æ‰¹é‡åˆ†æä¼šè¯åˆ›å»ºæˆåŠŸ"
        )
    except Exception as e:
        logger.error(f"[æ‰¹é‡åˆ†æ] åˆ›å»ºä¼šè¯å¤±è´¥ - error={str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºæ‰¹é‡åˆ†æä¼šè¯å¤±è´¥: {str(e)}"
        )


@router.get("/batch/sessions", response_model=SuccessResponse)
async def get_batch_sessions(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–æ‰¹é‡åˆ†æä¼šè¯åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[æ‰¹é‡åˆ†æ] æŸ¥è¯¢ä¼šè¯åˆ—è¡¨ - user_id={current_user.id}")
    
    # 1. æŸ¥è¯¢æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    query = db.query(BatchAnalysisSession).filter(
        BatchAnalysisSession.user_id == current_user.id
    ).order_by(BatchAnalysisSession.created_at.desc())
    
    # 2. åˆ†é¡µ
    total = query.count()
    sessions = query.offset((page - 1) * page_size).limit(page_size).all()
    
    # 3. æ„å»ºå“åº”æ•°æ®
    sessions_data = []
    for session in sessions:
        sessions_data.append({
            "id": session.id,
            "original_file_name": session.original_file_name,
            "sheet_count": session.sheet_count,
            "status": session.status,
            "created_at": session.created_at.isoformat() if session.created_at else None,
            "updated_at": session.updated_at.isoformat() if session.updated_at else None
        })
    
    return SuccessResponse(
        data={
            "sessions": sessions_data,
            "pagination": {
                "page": page,
                "page_size": page_size,
                "total": total,
                "pages": (total + page_size - 1) // page_size
            }
        },
        message="ä¼šè¯åˆ—è¡¨æŸ¥è¯¢æˆåŠŸ"
    )


@router.delete("/batch/sessions/{batch_session_id}", response_model=SuccessResponse)
async def delete_batch_session(
    batch_session_id: int = PathParam(..., description="æ‰¹é‡ä¼šè¯ID"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    åˆ é™¤æ‰¹é‡åˆ†æä¼šè¯ï¼ˆç®€åŒ–ç‰ˆï¼Œç§»é™¤project_idå‚æ•°ï¼‰
    """
    logger.info(f"[æ‰¹é‡åˆ†æ] åˆ é™¤ä¼šè¯ - batch_session_id={batch_session_id}, user_id={current_user.id}")
    
    try:
        # 1. æŸ¥è¯¢æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = db.query(BatchAnalysisSession).filter(
            BatchAnalysisSession.id == batch_session_id,
            BatchAnalysisSession.user_id == current_user.id
        ).first()
        
        if not batch_session:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æ‰¹é‡ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. åˆ é™¤ä¼šè¯ï¼ˆçº§è”åˆ é™¤ä¼šåŒæ—¶åˆ é™¤ç›¸å…³çš„SheetReportè®°å½•ï¼‰
        db.delete(batch_session)
        db.commit()
        
        logger.info(f"[æ‰¹é‡åˆ†æ] ä¼šè¯åˆ é™¤æˆåŠŸ - batch_session_id={batch_session_id}")
        
        return SuccessResponse(
            data={"deleted_id": batch_session_id},
            message="ä¼šè¯åˆ é™¤æˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[æ‰¹é‡åˆ†æ] åˆ é™¤ä¼šè¯å¤±è´¥ - batch_session_id={batch_session_id}, error={str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}"
        )


# ==================== å®šåˆ¶åŒ–æ‰¹é‡åˆ†æç›¸å…³API ====================

@router.post("/custom-batch/upload", response_model=SuccessResponse)
async def upload_custom_batch_excel(
    file: UploadFile = File(...),
    analysis_request: str = Form("ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    ä¸Šä¼ å¤šSheet Excelæ–‡ä»¶å¹¶æ‹†åˆ†ï¼ˆå®šåˆ¶åŒ–æ‰¹é‡åˆ†æï¼‰
    æ‹†åˆ†å®Œæˆåè‡ªåŠ¨å¼€å§‹æ‰¹é‡åˆ†æ
    """
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] ä¸Šä¼ æ–‡ä»¶ - filename={file.filename}, user_id={current_user.id}")
    
    # 1. éªŒè¯æ–‡ä»¶
    if not file.filename:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
        )
    
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in ['.xlsx']:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ‰¹é‡åˆ†æåªæ”¯æŒ .xlsx æ ¼å¼çš„æ–‡ä»¶"
        )
    
    # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆ20MBï¼‰
    file_content = await file.read()
    file_size = len(file_content)
    max_size = 20 * 1024 * 1024  # 20MB
    
    if file_size > max_size:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡20MB"
        )
    
    try:
        # 2. åˆ›å»ºæ‰¹é‡ä¼šè¯è®°å½•ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = CustomBatchAnalysisSession(
            user_id=current_user.id,
            original_file_name=file.filename,
            original_file_path="",
            split_files_dir="",
            sheet_count=0,
            status="processing"
        )
        db.add(batch_session)
        db.flush()
        
        batch_session_id = batch_session.id
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åˆ›å»ºæ‰¹é‡ä¼šè¯ - batch_session_id={batch_session_id}")
        
        # 3. ä¿å­˜åŸå§‹æ–‡ä»¶ï¼ˆä½¿ç”¨custom_batchç›®å½•ï¼‰
        batch_dir = Path(f"uploads/operation/project_{DEFAULT_PROJECT_ID}/custom_batch/batch_{batch_session_id}")
        original_dir = batch_dir / "original"
        sheets_dir = batch_dir / "sheets"
        
        original_dir.mkdir(parents=True, exist_ok=True)
        sheets_dir.mkdir(parents=True, exist_ok=True)
        
        original_file_path = original_dir / file.filename
        with open(original_file_path, "wb") as f:
            f.write(file_content)
        
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åŸå§‹æ–‡ä»¶å·²ä¿å­˜ - path={original_file_path}")
        
        # 4. æ‹†åˆ†Excelæ–‡ä»¶
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] å¼€å§‹æ‹†åˆ†Excelæ–‡ä»¶...")
        split_files = ExcelService.split_excel_file(
            source_file_path=str(original_file_path),
            output_dir=sheets_dir,
            batch_session_id=batch_session_id
        )
        
        sheet_count = len(split_files)
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æ‹†åˆ†å®Œæˆ - sheet_count={sheet_count}")
        
        # éªŒè¯æ‰€æœ‰æ‹†åˆ†æ–‡ä»¶éƒ½å­˜åœ¨
        for sheet_info in split_files:
            split_path = Path(sheet_info["split_file_path"])
            if not split_path.exists():
                logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æ‹†åˆ†æ–‡ä»¶ä¸å­˜åœ¨: {split_path}")
                raise Exception(f"æ‹†åˆ†æ–‡ä»¶ä¸å­˜åœ¨: {split_path}")
        
        # 5. æ›´æ–°æ‰¹é‡ä¼šè¯è®°å½•
        batch_session.original_file_path = str(original_file_path)
        batch_session.split_files_dir = str(sheets_dir)
        batch_session.sheet_count = sheet_count
        
        # 6. ä¸ºæ¯ä¸ªSheetåˆ›å»ºæŠ¥å‘Šè®°å½•
        sheet_reports = []
        for sheet_info in split_files:
            sheet_report = CustomSheetReport(
                custom_batch_session_id=batch_session_id,
                sheet_name=sheet_info["sheet_name"],
                sheet_index=sheet_info["sheet_index"],
                split_file_path=sheet_info["split_file_path"],
                report_status="pending"
            )
            db.add(sheet_report)
            sheet_reports.append(sheet_report)
        
        db.commit()
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æ‰¹é‡ä¼šè¯å’ŒSheetæŠ¥å‘Šè®°å½•å·²åˆ›å»º")
        
        # 7. è¿”å›ç»“æœ
        return SuccessResponse(
            data={
                "batch_session_id": batch_session_id,
                "sheet_count": sheet_count,
                "sheets": [
                    {
                        "id": sr.id,
                        "sheet_name": sr.sheet_name,
                        "sheet_index": sr.sheet_index,
                        "split_file_path": sr.split_file_path,
                        "report_status": sr.report_status
                    }
                    for sr in sheet_reports
                ],
                "status": batch_session.status
            },
            message="æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå·²æ‹†åˆ†å®Œæˆ"
        )
    
    except Exception as e:
        db.rollback()
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] ä¸Šä¼ å’Œæ‹†åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ–‡ä»¶ä¸Šä¼ å’Œæ‹†åˆ†å¤±è´¥: {str(e)}"
        )


@router.post("/custom-batch/analyze", response_model=SuccessResponse)
async def start_custom_batch_analysis(
    batch_session_id: int = Form(...),
    analysis_request: str = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    å¼€å§‹å®šåˆ¶åŒ–æ‰¹é‡åˆ†æï¼ˆå¼‚æ­¥å¤„ç†ï¼‰
    å¤ç”¨ç°æœ‰çš„ generate_report é€»è¾‘ï¼Œå¯¹æ¯ä¸ªSheeté‡å¤è°ƒç”¨
    """
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] å¼€å§‹æ‰¹é‡åˆ†æ - batch_session_id={batch_session_id}, user_id={current_user.id}")
    
    try:
        # 1. è·å–æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = db.query(CustomBatchAnalysisSession).filter(
            CustomBatchAnalysisSession.id == batch_session_id,
            CustomBatchAnalysisSession.user_id == current_user.id
        ).first()
        
        if not batch_session:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æ‰¹é‡ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. è·å–æ‰€æœ‰å¾…å¤„ç†çš„SheetæŠ¥å‘Š
        sheet_reports = db.query(CustomSheetReport).filter(
            CustomSheetReport.custom_batch_session_id == batch_session_id,
            CustomSheetReport.report_status == "pending"
        ).order_by(CustomSheetReport.sheet_index).all()
        
        if not sheet_reports:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ²¡æœ‰å¾…å¤„ç†çš„SheetæŠ¥å‘Š"
            )
        
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æ‰¾åˆ° {len(sheet_reports)} ä¸ªå¾…å¤„ç†çš„Sheet")
        
        # 3. æ›´æ–°æ‰¹é‡ä¼šè¯çŠ¶æ€
        batch_session.status = "processing"
        db.commit()
        
        # 4. å¯åŠ¨å¼‚æ­¥ä»»åŠ¡å¤„ç†æ¯ä¸ªSheet
        async def run_batch_analysis():
            """åå°å¼‚æ­¥ä»»åŠ¡"""
            try:
                from app.core.database import SessionLocal
                background_db = SessionLocal()
                
                try:
                    background_sheet_reports = background_db.query(CustomSheetReport).filter(
                        CustomSheetReport.custom_batch_session_id == batch_session_id
                    ).order_by(CustomSheetReport.sheet_index).all()
                    
                    # å¹¶å‘å¤„ç†æ‰€æœ‰Sheetï¼ˆä½¿ç”¨å®šåˆ¶åŒ–æ‰¹é‡åˆ†æå‡½æ•°ï¼‰
                    results = await process_all_custom_sheets_concurrently(
                        sheet_reports=background_sheet_reports,
                        analysis_request=analysis_request,
                        user_id=current_user.id,
                        batch_session_id=batch_session_id,
                        db=background_db
                    )
                    
                    # æ›´æ–°æ‰¹é‡ä¼šè¯çŠ¶æ€
                    background_batch_session = background_db.query(CustomBatchAnalysisSession).filter(
                        CustomBatchAnalysisSession.id == batch_session_id
                    ).first()
                    
                    if background_batch_session:
                        completed_count = background_db.query(CustomSheetReport).filter(
                            CustomSheetReport.custom_batch_session_id == batch_session_id,
                            CustomSheetReport.report_status == "completed"
                        ).count()
                        
                        failed_count = background_db.query(CustomSheetReport).filter(
                            CustomSheetReport.custom_batch_session_id == batch_session_id,
                            CustomSheetReport.report_status == "failed"
                        ).count()
                        
                        total_count = background_batch_session.sheet_count
                        
                        if completed_count == total_count:
                            background_batch_session.status = "completed"
                        elif failed_count == total_count:
                            background_batch_session.status = "failed"
                        elif failed_count > 0:
                            background_batch_session.status = "partial_failed"
                        else:
                            background_batch_session.status = "processing"
                        
                        background_db.commit()
                        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æ‰¹é‡åˆ†æå®Œæˆ - batch_session_id={batch_session_id}, completed={completed_count}, failed={failed_count}")
                
                finally:
                    background_db.close()
            
            except Exception as e:
                logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åå°ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
                from app.core.database import SessionLocal
                error_db = SessionLocal()
                try:
                    error_batch_session = error_db.query(CustomBatchAnalysisSession).filter(
                        CustomBatchAnalysisSession.id == batch_session_id
                    ).first()
                    if error_batch_session:
                        error_batch_session.status = "failed"
                        error_db.commit()
                finally:
                    error_db.close()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        asyncio.create_task(run_batch_analysis())
        
        # 5. è¿”å›å¤„ç†çŠ¶æ€
        return SuccessResponse(
            data={
                "batch_session_id": batch_session_id,
                "status": "processing",
                "total_sheets": len(sheet_reports),
                "completed_sheets": 0
            },
            message="æ‰¹é‡åˆ†æå·²å¼€å§‹ï¼Œæ­£åœ¨åå°å¤„ç†"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] å¯åŠ¨æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯åŠ¨æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}"
        )


@router.get("/custom-batch/{batch_session_id}/status", response_model=SuccessResponse)
async def get_custom_batch_analysis_status(
    batch_session_id: int = PathParam(..., description="æ‰¹é‡ä¼šè¯ID"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–å®šåˆ¶åŒ–æ‰¹é‡åˆ†æçŠ¶æ€
    """
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æŸ¥è¯¢çŠ¶æ€ - batch_session_id={batch_session_id}, user_id={current_user.id}")
    
    # 1. è·å–æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    batch_session = db.query(CustomBatchAnalysisSession).filter(
        CustomBatchAnalysisSession.id == batch_session_id,
        CustomBatchAnalysisSession.user_id == current_user.id
    ).first()
    
    if not batch_session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ‰¹é‡ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
        )
    
    # 2. è·å–æ‰€æœ‰SheetæŠ¥å‘Š
    sheet_reports = db.query(CustomSheetReport).filter(
        CustomSheetReport.custom_batch_session_id == batch_session_id
    ).order_by(CustomSheetReport.sheet_index).all()
    
    # 3. ç»Ÿè®¡çŠ¶æ€
    total_sheets = len(sheet_reports)
    completed_sheets = sum(1 for sr in sheet_reports if sr.report_status == "completed")
    failed_sheets = sum(1 for sr in sheet_reports if sr.report_status == "failed")
    generating_sheets = sum(1 for sr in sheet_reports if sr.report_status == "generating")
    
    # 4. æ„å»ºæŠ¥å‘Šåˆ—è¡¨
    reports_data = []
    for sr in sheet_reports:
        report_data = {
            "id": sr.id,
            "sheet_name": sr.sheet_name,
            "sheet_index": sr.sheet_index,
            "report_status": sr.report_status,
        }
        
        if sr.report_status == "completed" and sr.report_content:
            report_data["report_content"] = sr.report_content
        elif sr.report_status == "failed" and sr.error_message:
            report_data["error_message"] = sr.error_message
        
        reports_data.append(report_data)
    
    return SuccessResponse(
        data={
            "batch_session_id": batch_session_id,
            "status": batch_session.status,
            "total_sheets": total_sheets,
            "completed_sheets": completed_sheets,
            "failed_sheets": failed_sheets,
            "generating_sheets": generating_sheets,
            "pending_sheets": total_sheets - completed_sheets - failed_sheets - generating_sheets,
            "reports": reports_data
        },
        message="çŠ¶æ€æŸ¥è¯¢æˆåŠŸ"
    )


@router.get("/custom-batch/reports/{report_id}", response_model=SuccessResponse)
async def get_custom_sheet_report(
    report_id: int = PathParam(..., description="æŠ¥å‘ŠID"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–å•ä¸ªæŠ¥å‘Šè¯¦æƒ…ï¼ˆå®šåˆ¶åŒ–æ‰¹é‡åˆ†æï¼‰
    """
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æŸ¥è¯¢æŠ¥å‘Šè¯¦æƒ… - report_id={report_id}, user_id={current_user.id}")
    
    # 1. è·å–æŠ¥å‘Š
    sheet_report = db.query(CustomSheetReport).filter(
        CustomSheetReport.id == report_id
    ).first()
    
    if not sheet_report:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æŠ¥å‘Šä¸å­˜åœ¨"
        )
    
    # 2. éªŒè¯æƒé™ï¼ˆé€šè¿‡æ‰¹é‡ä¼šè¯éªŒè¯ï¼Œä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    batch_session = db.query(CustomBatchAnalysisSession).filter(
        CustomBatchAnalysisSession.id == sheet_report.custom_batch_session_id,
        CustomBatchAnalysisSession.user_id == current_user.id
    ).first()
    
    if not batch_session:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒé™è®¿é—®æ­¤æŠ¥å‘Š"
        )
    
    # 3. æ„å»ºå“åº”æ•°æ®
    report_data = {
        "id": sheet_report.id,
        "sheet_name": sheet_report.sheet_name,
        "sheet_index": sheet_report.sheet_index,
        "report_status": sheet_report.report_status,
        "report_content": sheet_report.report_content or {},
        "error_message": sheet_report.error_message,
        "created_at": sheet_report.created_at.isoformat() if sheet_report.created_at else None,
        "updated_at": sheet_report.updated_at.isoformat() if sheet_report.updated_at else None
    }
    
    return SuccessResponse(
        data=report_data,
        message="æŠ¥å‘ŠæŸ¥è¯¢æˆåŠŸ"
    )


@router.post("/custom-batch/reports/{report_id}/download")
async def download_custom_batch_report_pdf(
    report_id: int = PathParam(..., description="æŠ¥å‘ŠID"),
    request_data: DownloadBatchReportRequest = Body(...),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    ä¸‹è½½å®šåˆ¶åŒ–æ‰¹é‡åˆ†ææŠ¥å‘ŠPDFï¼ˆæ”¯æŒå›¾è¡¨å›¾ç‰‡ï¼‰
    """
    import traceback
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] ====== å¼€å§‹ä¸‹è½½æŠ¥å‘ŠPDF ======")
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] report_id={report_id}, user_id={current_user.id}")
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æ”¶åˆ° {len(request_data.chart_images) if request_data.chart_images else 0} ä¸ªå›¾è¡¨å›¾ç‰‡")
    
    try:
        # 1. è·å–SheetæŠ¥å‘Š
        sheet_report = db.query(CustomSheetReport).filter(
            CustomSheetReport.id == report_id
        ).first()
        
        if not sheet_report:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æŠ¥å‘Šä¸å­˜åœ¨"
            )
        
        # 2. éªŒè¯æƒé™ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = db.query(CustomBatchAnalysisSession).filter(
            CustomBatchAnalysisSession.id == sheet_report.custom_batch_session_id,
            CustomBatchAnalysisSession.user_id == current_user.id
        ).first()
        
        if not batch_session:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒé™è®¿é—®æ­¤æŠ¥å‘Š"
            )
        
        # 3. æ£€æŸ¥æŠ¥å‘ŠçŠ¶æ€å’Œå†…å®¹
        if sheet_report.report_status != "completed":
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"æŠ¥å‘Šå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {sheet_report.report_status}"
            )
        
        if not sheet_report.report_content:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æŠ¥å‘Šå†…å®¹ä¸å­˜åœ¨"
            )
        
        # 4. è·å–æŠ¥å‘Šå†…å®¹
        report_content = {
            "text": str(sheet_report.report_content.get("text", "")),
            "charts": sheet_report.report_content.get("charts", []) or [],
            "tables": sheet_report.report_content.get("tables", []) or [],
            "metrics": sheet_report.report_content.get("metrics", {}) or {}
        }
        
        if not report_content.get("text"):
            report_content["text"] = "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
        
        # 5. å¤„ç†å›¾è¡¨å›¾ç‰‡
        chart_images_data = []
        if request_data.chart_images:
            for chart_img in request_data.chart_images:
                try:
                    image_data = chart_img.image.split(',')[1] if ',' in chart_img.image else chart_img.image
                    chart_images_data.append({
                        'index': chart_img.index,
                        'title': chart_img.title,
                        'image_data': image_data
                    })
                except Exception as e:
                    logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] âœ— è§£æå›¾è¡¨å›¾ç‰‡å¤±è´¥: {str(e)}")
        
        # 6. ç”ŸæˆPDF
        try:
            from app.utils.pdf_generator import generate_report_pdf
            
            report_title = f"{sheet_report.sheet_name} - æ•°æ®åˆ†ææŠ¥å‘Š"
            pdf_bytes = generate_report_pdf(
                title=report_title,
                report_content=report_content,
                session_id=sheet_report.custom_batch_session_id,
                chart_images=chart_images_data
            )
            logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] PDFç”ŸæˆæˆåŠŸ - å¤§å°: {len(pdf_bytes)} bytes")
        except Exception as e:
            logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] PDFç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"PDFç”Ÿæˆå¤±è´¥: {str(e)}"
            )
        
        # 7. è¿”å›PDFæ–‡ä»¶
        filename = f"{sheet_report.sheet_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        
        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"'
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_traceback = traceback.format_exc()
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] ====== PDFä¸‹è½½å¤±è´¥ ======")
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] é”™è¯¯æ¶ˆæ¯: {str(e)}")
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] å®Œæ•´å †æ ˆ:\n{error_traceback}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç”ŸæˆPDFå¤±è´¥: {str(e)}"
        )


@router.post("/custom-batch/sessions", response_model=SuccessResponse)
async def create_custom_batch_session(
    request_data: Optional[dict] = Body(default=None),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    åˆ›å»ºæ–°çš„å®šåˆ¶åŒ–æ‰¹é‡åˆ†æä¼šè¯
    """
    title = request_data.get("title") if request_data else None
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åˆ›å»ºä¼šè¯ - user_id={current_user.id}, title={title}")
    
    try:
        # ç”Ÿæˆæ ‡é¢˜
        if not title:
            title = f"å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # åˆ›å»ºæ‰¹é‡ä¼šè¯ï¼ˆåˆå§‹çŠ¶æ€ä¸ºdraftï¼Œç­‰å¾…ä¸Šä¼ æ–‡ä»¶ï¼‰
        batch_session = CustomBatchAnalysisSession(
            user_id=current_user.id,
            original_file_name=title,
            original_file_path="",
            split_files_dir="",
            sheet_count=0,
            status="draft"  # è‰ç¨¿çŠ¶æ€ï¼Œç­‰å¾…ä¸Šä¼ æ–‡ä»¶
        )
        db.add(batch_session)
        db.commit()
        db.refresh(batch_session)
        
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] ä¼šè¯åˆ›å»ºæˆåŠŸ - batch_session_id={batch_session.id}, title={batch_session.original_file_name}")
        
        # è¿”å›å“åº”
        return SuccessResponse(
            data={
                "id": batch_session.id,
                "original_file_name": batch_session.original_file_name,
                "sheet_count": batch_session.sheet_count,
                "status": batch_session.status,
                "created_at": batch_session.created_at.isoformat() if batch_session.created_at else None,
                "updated_at": batch_session.updated_at.isoformat() if batch_session.updated_at else None
            },
            message="å®šåˆ¶åŒ–æ‰¹é‡åˆ†æä¼šè¯åˆ›å»ºæˆåŠŸ"
        )
    except Exception as e:
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åˆ›å»ºä¼šè¯å¤±è´¥ - error={str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºå®šåˆ¶åŒ–æ‰¹é‡åˆ†æä¼šè¯å¤±è´¥: {str(e)}"
        )


@router.get("/custom-batch/sessions", response_model=SuccessResponse)
async def get_custom_batch_sessions(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–å®šåˆ¶åŒ–æ‰¹é‡åˆ†æä¼šè¯åˆ—è¡¨
    """
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] æŸ¥è¯¢ä¼šè¯åˆ—è¡¨ - user_id={current_user.id}")
    
    # 1. æŸ¥è¯¢æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
    query = db.query(CustomBatchAnalysisSession).filter(
        CustomBatchAnalysisSession.user_id == current_user.id
    ).order_by(CustomBatchAnalysisSession.created_at.desc())
    
    # 2. åˆ†é¡µ
    total = query.count()
    sessions = query.offset((page - 1) * page_size).limit(page_size).all()
    
    # 3. æ„å»ºå“åº”æ•°æ®
    sessions_data = []
    for session in sessions:
        sessions_data.append({
            "id": session.id,
            "original_file_name": session.original_file_name,
            "sheet_count": session.sheet_count,
            "status": session.status,
            "created_at": session.created_at.isoformat() if session.created_at else None,
            "updated_at": session.updated_at.isoformat() if session.updated_at else None
        })
    
    return SuccessResponse(
        data={
            "sessions": sessions_data,
            "pagination": {
                "page": page,
                "page_size": page_size,
                "total": total,
                "pages": (total + page_size - 1) // page_size
            }
        },
        message="ä¼šè¯åˆ—è¡¨æŸ¥è¯¢æˆåŠŸ"
    )


@router.delete("/custom-batch/sessions/{batch_session_id}", response_model=SuccessResponse)
async def delete_custom_batch_session(
    batch_session_id: int = PathParam(..., description="æ‰¹é‡ä¼šè¯ID"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    åˆ é™¤å®šåˆ¶åŒ–æ‰¹é‡åˆ†æä¼šè¯
    """
    logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åˆ é™¤ä¼šè¯ - batch_session_id={batch_session_id}, user_id={current_user.id}")
    
    try:
        # 1. æŸ¥è¯¢æ‰¹é‡ä¼šè¯ï¼ˆä½¿ç”¨å›ºå®šé¡¹ç›®IDï¼‰
        batch_session = db.query(CustomBatchAnalysisSession).filter(
            CustomBatchAnalysisSession.id == batch_session_id,
            CustomBatchAnalysisSession.user_id == current_user.id
        ).first()
        
        if not batch_session:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æ‰¹é‡ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # 2. åˆ é™¤ä¼šè¯ï¼ˆçº§è”åˆ é™¤ä¼šåŒæ—¶åˆ é™¤ç›¸å…³çš„CustomSheetReportè®°å½•ï¼‰
        db.delete(batch_session)
        db.commit()
        
        logger.info(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] ä¼šè¯åˆ é™¤æˆåŠŸ - batch_session_id={batch_session_id}")
        
        return SuccessResponse(
            data={"deleted_id": batch_session_id},
            message="ä¼šè¯åˆ é™¤æˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[å®šåˆ¶åŒ–æ‰¹é‡åˆ†æ] åˆ é™¤ä¼šè¯å¤±è´¥ - batch_session_id={batch_session_id}, error={str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}"
        )


# ==================== AIå¯¹è¯API ====================

@router.post("/dialog/stream")
async def dialog_stream(
    session_id: int = Form(...),
    user_message: str = Form(...),
    conversation_id: Optional[str] = Form(None),
    current_charts: str = Form("[]"),
    current_report_text: str = Form(""),
    current_html_charts: str = Form(""),
    selected_text: Optional[str] = Form(None),
    selected_text_context: Optional[str] = Form(None),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    æµå¼AIå¯¹è¯æ¥å£ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ï¼‰
    æ”¯æŒæŠ¥å‘Šæ–‡å­—ä¿®æ”¹ã€å†…å®¹æ·»åŠ ã€å¯¹è¯äº¤äº’ç­‰åŠŸèƒ½
    è¿”å› SSE (Server-Sent Events) æ ¼å¼çš„æµå¼å“åº”
    """
    from app.services.bailian_dialog_service_stream import BailianDialogServiceStream
    from app.services.dialog_manager import DialogManager

    logger.info(f"[AIå¯¹è¯] æ”¶åˆ°æµå¼å¯¹è¯è¯·æ±‚ - session_id={session_id}, user_id={current_user.id}")
    logger.info(f"[AIå¯¹è¯] ç”¨æˆ·æ¶ˆæ¯: {user_message[:100]}...")

    # è§£æå‚æ•°
    try:
        charts_list = json.loads(current_charts) if current_charts else []
    except json.JSONDecodeError:
        charts_list = []

    context_dict = None
    if selected_text_context:
        try:
            context_dict = json.loads(selected_text_context)
        except json.JSONDecodeError:
            pass

    if selected_text:
        logger.info(f"[AIå¯¹è¯] é€‰ä¸­æ–‡å­—é•¿åº¦: {len(selected_text)}")

    # è·å–å¯¹è¯å†å²ï¼ˆä»æ•°æ®åº“ï¼‰
    dialog_manager = DialogManager()
    dialog_history = dialog_manager.get_messages_for_ai(db, session_id, limit=20)
    logger.info(f"[AIå¯¹è¯] è·å–åˆ°å†å²å¯¹è¯ {len(dialog_history)} æ¡")

    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
    dialog_manager.save_message_to_db(
        db=db,
        session_id=session_id,
        role="user",
        content=user_message,
        extra_data={"selected_text": selected_text} if selected_text else None
    )

    # åˆ›å»ºæµå¼å¯¹è¯æœåŠ¡
    dialog_service = BailianDialogServiceStream()

    async def generate_sse():
        """ç”Ÿæˆ SSE æ ¼å¼çš„æµå¼å“åº”"""
        ai_response = ""
        action_type = "chat"

        try:
            async for chunk in dialog_service.process_dialog_message_stream(
                session_id=str(session_id),
                user_message=user_message,
                current_charts=charts_list,
                conversation_id=conversation_id,
                current_report_text=current_report_text,
                current_html_charts=current_html_charts,
                selected_text=selected_text,
                selected_text_context=context_dict,
                dialog_history=dialog_history
            ):
                # æ”¶é›†AIå›å¤å†…å®¹
                if chunk.get("type") == "content":
                    ai_response += chunk.get("content", "")
                elif chunk.get("type") == "done":
                    data = chunk.get("data", {})
                    ai_response = data.get("response", ai_response)
                    action_type = data.get("action_type", "chat")

                # å°†æ¯ä¸ª chunk è½¬æ¢ä¸º SSE æ ¼å¼
                yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

            # ä¿å­˜AIå›å¤åˆ°æ•°æ®åº“
            if ai_response:
                dialog_manager.save_message_to_db(
                    db=db,
                    session_id=session_id,
                    role="assistant",
                    content=ai_response,
                    extra_data={"action_type": action_type}
                )
                logger.debug(f"[AIå¯¹è¯] å·²ä¿å­˜AIå›å¤åˆ°æ•°æ®åº“ - session_id={session_id}")

        except Exception as e:
            logger.error(f"[AIå¯¹è¯] æµå¼å¤„ç†å¼‚å¸¸: {str(e)}")
            error_chunk = {
                "type": "error",
                "content": f"å¤„ç†å¤±è´¥: {str(e)}"
            }
            yield f"data: {json.dumps(error_chunk, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        generate_sse(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.post("/dialog")
async def dialog_non_stream(
    session_id: int = Form(...),
    user_message: str = Form(...),
    conversation_id: Optional[str] = Form(None),
    current_charts: str = Form("[]"),
    current_report_text: str = Form(""),
    current_html_charts: str = Form(""),
    selected_text: Optional[str] = Form(None),
    selected_text_context: Optional[str] = Form(None),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    éæµå¼AIå¯¹è¯æ¥å£ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
    """
    from app.services.bailian_dialog_service import BailianDialogService
    
    logger.info(f"[AIå¯¹è¯] æ”¶åˆ°éæµå¼å¯¹è¯è¯·æ±‚ - session_id={session_id}, user_id={current_user.id}")
    
    # è§£æå‚æ•°
    try:
        charts_list = json.loads(current_charts) if current_charts else []
    except json.JSONDecodeError:
        charts_list = []
    
    context_dict = None
    if selected_text_context:
        try:
            context_dict = json.loads(selected_text_context)
        except json.JSONDecodeError:
            pass
    
    try:
        dialog_service = BailianDialogService()
        result = await dialog_service.process_dialog_message(
            session_id=str(session_id),
            user_message=user_message,
            current_charts=charts_list,
            conversation_id=conversation_id,
            current_report_text=current_report_text,
            current_html_charts=current_html_charts,
            selected_text=selected_text,
            selected_text_context=context_dict
        )
        
        return SuccessResponse(
            data=result,
            message="å¯¹è¯å¤„ç†æˆåŠŸ"
        )
    except Exception as e:
        logger.error(f"[AIå¯¹è¯] å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}"
        )


@router.get("/dialog/history")
async def get_dialog_history(
    session_id: int = Query(..., description="ä¼šè¯ID"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ¶ˆæ¯æ•°é‡é™åˆ¶"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    è·å–å¯¹è¯å†å²è®°å½•ï¼ˆä»DialogHistoryè¡¨è¯»å–ï¼Œæ”¯æŒç‰ˆæœ¬æ ‡è®°ï¼‰
    """
    from app.models.dialog_history import DialogHistory
    from app.models.session_version import AnalysisSessionVersion
    
    logger.info(f"[AIå¯¹è¯] è·å–å¯¹è¯å†å² - session_id={session_id}, user_id={current_user.id}")
    
    try:
        # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == session_id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # ä»DialogHistoryè¡¨è·å–å¯¹è¯å†å²
        dialog_records = db.query(DialogHistory).filter(
            DialogHistory.session_id == session_id
        ).order_by(DialogHistory.created_at.asc()).limit(limit).all()
        
        # è·å–æ‰€æœ‰ç‰ˆæœ¬ä¿¡æ¯ï¼ˆç”¨äºæ ‡è®°ï¼‰
        versions = db.query(AnalysisSessionVersion).filter(
            AnalysisSessionVersion.session_id == session_id
        ).order_by(AnalysisSessionVersion.created_at.asc()).all()
        
        version_map = {v.id: v for v in versions}
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        for record in dialog_records:
            msg = record.to_dict()
            
            # å¦‚æœæœ‰ç‰ˆæœ¬æ ‡è®°ï¼Œæ·»åŠ ç‰ˆæœ¬ä¿¡æ¯
            if record.version_id and record.version_id in version_map:
                version = version_map[record.version_id]
                msg['version_marker'] = {
                    'version_id': version.id,
                    'version_no': version.version_no,
                    'summary': version.summary,
                    'created_at': version.created_at.isoformat() if version.created_at else None
                }
            
            messages.append(msg)
        
        logger.info(f"[AIå¯¹è¯] è·å–å¯¹è¯å†å²æˆåŠŸ - session_id={session_id}, count={len(messages)}")
        
        return SuccessResponse(
            data={"messages": messages},
            message="è·å–å¯¹è¯å†å²æˆåŠŸ"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[AIå¯¹è¯] è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}"
        )


@router.delete("/dialog/history")
async def clear_dialog_history(
    session_id: int = Query(..., description="ä¼šè¯ID"),
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    æ¸…é™¤å¯¹è¯å†å²è®°å½•ï¼ˆä»DialogHistoryè¡¨åˆ é™¤ï¼‰
    """
    from app.models.dialog_history import DialogHistory
    
    logger.info(f"[AIå¯¹è¯] æ¸…é™¤å¯¹è¯å†å² - session_id={session_id}, user_id={current_user.id}")
    
    try:
        function_key = "operation_data_analysis"
        conversation = db.query(AnalysisSession).filter(
            AnalysisSession.id == session_id,
            AnalysisSession.function_key == function_key,
            AnalysisSession.user_id == current_user.id
        ).first()
        
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
            )
        
        # åˆ é™¤DialogHistoryè¡¨ä¸­çš„è®°å½•
        db.query(DialogHistory).filter(
            DialogHistory.session_id == session_id
        ).delete()
        
        # åŒæ—¶æ¸…ç©ºä¼šè¯çš„messageså­—æ®µï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        conversation.messages = []
        db.commit()
        
        logger.info(f"[AIå¯¹è¯] å¯¹è¯å†å²å·²æ¸…é™¤ - session_id={session_id}")
        
        return SuccessResponse(
            data={"session_id": session_id},
            message="å¯¹è¯å†å²å·²æ¸…é™¤"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[AIå¯¹è¯] æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {str(e)}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {str(e)}"
        )


